\begin{algorithm}[H]
    \DontPrintSemicolon
    \KwData{Trainingsdatensatz \(D\), wobei \(x_i \in \mathcal{X}\) und \(y_i \in \{-1, 1\}\); Anzahl der Iterationen \(T\).}
    \KwResult{Finale Klassifikationsfunktion: \(H(x) = \text{sign}\left(\sum_{t=1}^{T} \alpha_t h_t(x)\right)\).}
    \BlankLine
    \tcp{Initialisiere Gewichte}
    \(\mathcal{D}_1(i)=\frac{1}{n}\)\;
    \For{\(t = 1\) \KwTo \(T\)}{
        \tcp{Trainiere einen schwachen Lerner unter Berücksichtigung der Gewichtung \(\mathcal{D}_t(i)\)}
        \(h_t \leftarrow \mathcal{L}(D, \mathcal{D}_t)\) \;
        \tcp{Berechne den gewichteten Fehler}
        \(\varepsilon_t = \sum_{i=1}^{n} \mathcal{D}_t(i) I(y_i \neq h_t(x_i))\)\;
        Wähle den Lerner mit dem geringsten Fehler als \(h_t\)\;
        \If{\(\varepsilon_t > 0.5\)}{\textbf{break}}\;
        \tcp{Berechne den Lernerkoeffizienten}
        \(\alpha_t = \frac{1}{2} \ln \left( \frac{1 - \varepsilon_t}{\varepsilon_t} \right)\)\;
        % End of Part 1, save last line number if needed
        \tcp{Algorithmus wird fortgesetzt...}
    }
\end{algorithm}