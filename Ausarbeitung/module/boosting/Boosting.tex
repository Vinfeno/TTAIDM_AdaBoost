Boosting ist eine Ensemble-Technik im Machine Learning, die mehrere sog. \emph{\glqq schwache Lerner\grqq} kombiniert,
um ein präziseres Gesamtmodell zu erstellen. Als \emph{schwacher Lerner} wird ein Modell bezeichnet, das nur einen geringen
Zusammenhang in den Daten lernen kann und dessen Vorhersagen daher nur etwas besser als zufälliges Raten sind.
In jeder Iteration wird ein solches Modell trainiert, das versucht, falsche
Vorhersagen der vorherigen Modelle zu korrigieren, indem es die Gewichtung der Trainingsdaten anpasst.
Das Ziel ist es, den systematischen Fehler (\emph{Bias}) des Modells zu reduzieren, der durch die einseitige
Betrachtung der Daten entsteht. Dadurch wird in de Regel eine bessere Generalisierbarkeit, also Genauigkeit auf
ungesehenen Daten erhöht.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{"./figures/Boosting_Graph"}
    \caption{Flussdiagramm zur Veranschaulichung des Boosting-Konzepts}
\end{figure}

\subsection*{Beispiel:}
(P(Iteration) = Vorhersage, W(Iteration) = Gewichtung)\\
\begin{center}
    \input{module/boosting/BoostingTabelle2.tex}
    \input{module/boosting/BoostingTabelle3.tex}\\[5pt]
    \emph{Beispielhafte Anpassung der Gewichte über die Iterationen}
\end{center}
